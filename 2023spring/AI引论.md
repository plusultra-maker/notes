# Artificial Intelligence (feat.CS-188n)

Searching
## 暴力：DFS&BFS
- 数据结构
  - 搜索是非线性的，因此需要数据结构来储存过程信息
  - DFS——到底回退——栈，BFS——顺序的同步前进——队列
- python 实现
```python
    class BFS:

```
  
## UCS(uniform cost search)
- 当解法有成本，路径有加权时，DFS和BFS找到的解的顺序是随机的，不能直接找到最优解
- 自然的想法——成本优先
  - 每次把一定成本可以到达的点全部取到，作为可能解路径的一部分，一点点增加成本范围；
  - 而如果在更高的成本达到了曾经达到过的点，则高成本的路径就不需要再考虑了，从而减少搜索次数
- 算法完毕，找到的一定是最优解
- 局限性：
  - 解是有限距离内的才可搜到（本质上是因为仍是暴力搜索）
  - 边权必须是正的，否则点的成本排序可能与搜索的顺序不同
  - 单向的，没有利用目标的信息
- 实现
  - priority queue
    - 维护“一次achievable”的点列，以其成本维持优先队列，每次纳入第一个点到已知路径集
    - 题外话，优先队列不一定是严格单调(维护需要O(n))，只需要保证首项最小——最小堆，O(logn)
- 
  ```python
  ``` 
## 有信息搜索（informed search）
- 人类看地图找路的时候，首先是既看起点，也看是不是这条路会离目标越来越远，可否借用
  - ps.但人类在迷宫上就没有地图上智慧，这是地图的性质，我们能否度量？
- 启发 heuristic
  - 用一个启发函数衡量“离目标距离”，但这个距离也需要算法计算
  - 这里我们先假设这个启发估计是已知的
- 贪心搜索
  - 仍是从起点出发，这次我们利用信息直接去我们能到达的点中距离目标最近的点，不断迭代
  - 问题：
    - 没有考虑去那个点的代价
    - 估计不一定准
    - 这样一定对吗——很可能某一步选错了（譬如某一条边权非常大，但对应的点距离目标很近，加起来仍是不划算），之后所有的选择都是这个错误的子树中，最终还需要返回重新搜；而且我们不知道搜出来的是不是最小的
- A*
  - 为了解决上面的问题，那就必须把该加起来的加起来，从而试图保证准确性和稳定性
  - 从起点出发，把每个可达点的值标记为 从起点到达这个点的累计（最小）权g+这个点的启发距离h
    - $f(n)=g(n)+h(n)$
    - 本质不是在排列点，而是在排列此刻已知路径上可选择发展的下一步中最小的
  - 仍然维持优先队列，直到目标被移除优先队列，那权值可知。想知道路径就可以记录每一个点的最小权路径的父节点，从目标反查即可
  - 特点：
    - 如果启发完全准确，理论上一定是对的（可以反证）
    - 是给盲目的UCS加上了目标点“方向”的信息，从而减少了向其他方向不必要的搜索
    - 启发估计如果不准确，那可以导致搜到的结果并不是最好的
- 可接受启发admissible：
  - 假设启发全是0，没有信息，那回到UCS，结果不会错但算法结束会更慢
  - 假设启发是大于真实距离的，而且和真实距离有出入，可能出现一个本应下一步被搜到的点，因为被赋予了较大的假距离，而停滞在了优先队列的深处
    - 导致搜索长期在迷失错误的子树，降低效率
    - 可能导致搜索在错误的子树里走到目标，得到错误的结果
    - 问：怎么保证至少结果不要错？
  - 可接受的：
    - 要求$ 0\leq h(n)\leq {h}^{*}(n) $，其中${h}^{*}(n)$是真实的代价
    - WHY？：
      - 我们需要证明，终点目标A一定被最优的路径下搜索到，在算法里体现为，A的所有最优路径前序节点一定在A之前离开队列，这样A就不会被非最优的路径搜索到
      - 反证法：假设我们以非最优的路径搜索到B点，B点下A是achievable的，则此时:$$f(b)\geq g(b) ,since: h(b)\geq 0$$则此时，$f(a)=g(a)$即为非最优路径的总代价；
      而对于A的最优路径前序节点中，进入了优先队列但还没被排出的点x（易知一定存在，即本应走的那条岔路），$$f(x)=g(x)+h(x)\leq g(x)+h^{*}(x)$$即小于最优路径的总代价，那么x应该比A先出队列；
      递归地，所有A的最优路径前序节点都会在A之前出队列，那么A一定以最优路径被搜索到
    - A*比UCS好：更多信息，有方向性
    - 问题：在图中搜索时，可能产生在搜索进行时，由于搜出了新的点，一个已经被搜到过的点的g值降低了，此时需要将其重新放入优先队列再次排出，并记录新的g值以及父节点，以得到正确的搜索顺序
      - 这会导致需要的存储空间上升，运算量一定程度上升
      - 避免这种现象，需要保证启发是一致的consistency：对任意边的两端点，其启发值差不能大于边权

## CSP问题 
- 我们此前处理的问题称为 计划问题，特点是给出某种最优的方案（存在目标函数）。下面我们讨论CSP问题，目的是给出满足约束的解（identification problem）
- CSP factors
  - 变量 一系列变量构成解
  - 定义域
  - 约束
- 问题：
  - 更多的结构，指数级的复杂度，NP-hard————化为搜索问题，并尝试降低搜索损耗
  - 抽象化为一个constraint graph，可以发现图是稀疏还是密集，是不是树形结构，这样可以针对性的开发算法
  - 如何搜索，如何减少浪费，如何尽早发现错误
## CSP解法：
- 最传统的搜索逻辑：backtracking回溯，一种基于dfs的搜索
  1. 手动确定一个搜索的顺序（本质上是把图约化为树）
  2. 对于下一个未确定的变量或需要被更改的变量，只能用 没有用过的且不与之前元素冲突的值，如果不存在，则回溯到上一层，重复。直到找到解，或回溯到根节点无可用值。
- Filtering 过滤 [Note3](https://inst.eecs.berkeley.edu/~cs188/fa22/assets/notes/cs188-fa22-note03.pdf)
  - forward checking:通过一些机制来提前缩小未分配变量的定义域，从而减少分支数（即不去试错而直接剔除）
  - arc consistency:
    - 想法是当在一个给定的条件发生时（例如出现了新的变量赋值），此时可以直接通过图和约束检查那些待分配的变量（forward）,如果出现了必然导致矛盾的取值，则直接将剔出其定义域。
    - 实现：
      1. 首先，先将所有待分配的变量中，所有会与已分配变量直接矛盾的值剔除。
      2. 把所有constraint化为双箭头(arc)，维护一个由箭头组成的队列Q。
      3. 当从Q中移除一个i->j的箭头时，检查i上是否有值可能使得j无值可选；如果有，则从i的定义域剔出该值，并把所有未被赋值的点k且k->i的箭头重新放回Q中——意义是i的选项减小了，需要重新判断是否导致有新的k值使得i中无值可选。
      4. 直到Q空——没有可剔除的值，继续赋值搜索；发现某些点的没有值可选，要回溯。
    - AC-3 algorithm 
    - 特点：
      - 提前利用了约束的关系，从而有信息的剔除了一些值，减少了试错回溯的次数
      - 但判断的过程需要大量计算，需要权衡
      - 思想来自于k-consistency,即k-1的节点的任何子集都需要使得k节点有值可选。我们这里k=2。
- Ordering 顺序
  - 显然，我们的搜索需要确定点or选值的顺序，可以针对此进行优化
  - Minimum Remaining Values 
    - 优先选择剩余可选值较少的点来分配（比较直觉）
  - Least Constraining Value
    - 选值尽量选会导致更少的剔除的值（更有可能是解），但这需要额外的计算（比如arc consistency）
- Structure
  - exploit the structure to improve your solving strategy
  - 树形约束，约束中无环，则可以将复杂度降为$O(nd^2)$
    - 方法：
      - 随意选一个根节点，将其他节点排列为拓扑排序，只使用单向的arc（显然满足单向就必然满足双向）
      - 从后向前做arc consistancy排除（从后向前保证了不需要重复再添加arc）
      - 只要排除后的每个点都有选项，那从根向后必然可以一次搜到一个解
    - 这里的主要代价只在arc consistancy中，且是单向的:$f(d)*O(n)$
  - 类（reasonably close to）树形结构
    - cutset conditioning(割集调节)
    - 通过寻找一个图里的最小点集使得割去该集后，剩下的结构为树形，可以沿用前述方法
    - 复杂度$O(d^c(n−c)d^2)$,其中c为割集大小，显然有较小的割集的图更适宜用
- Local Search
  - heuristic启发式：用一个函数表达与解的距离，比如目前违反的constraint数
  - 初始随机分配解，之后每次变动一个变量使得违反的约束总数减少，直到为0
  - 总时间代价不会随n而爆炸，对于randomly generated CSP？友好
  - 缺点：
    - 计算时间与${numbers of constraionts}/{numbers of variables}$相关，可能存在一个很高的峰
    - 不完备：随机出来的；suboptimal：很可能陷在局部里，找到极值而非最值
    - 典型的例子是 maximize or minimize an objective function，对于这类最优化问题我们介绍三种算法：__hill-climbing, simulated annealing and genetic algorithms__
- Hill-Climbing Search
  - 基于贪心，向目前所处的地方邻域的更高处进行
    - 缺点：incomplete 陷于局部最大，或陷于高原，且在到达"shoulders"的时候会很慢
  - stochastic hill-climbing 随机上爬
    - selects an action randomly among the uphill move
  - Random-Restart hill-climbing 随机起点,多次试验取极值，trivially complete
- Simulated Annealing Search 模拟退火
  - 随机跳向下一个点,计算目标值变化$\Delta$
    - if $\Delta >0$ 则更新
    - else 则按$e^{\Delta /T}$概率更新
    - 其中T是一个随着跳的次数变多逐渐下降的温度函数（退火）
    > If temperature is decreased slowly enough then the simulated annealing algorithm will reach the global maximum with probability approaching 1.
- Genetic Algorithms 遗传算法
  - a variant of local beam search：模拟遗传过程
    - 用一个序列表示变量的取值，初始随机出一些序列，并按目标函数的值降序排列
    - 按这些值相关的概率，抽出一些对来配对(fitness function)
    - 在这些对上随机取断点(selection),再交叉换位（crossover）生成新的序列
    - 最后这些新序列的某些位置按一定几率变异，从而得到新的一组序列，并重复
  - 通过更高概率交叉优质的基因，从而得到取值更高的序列，适用于较大的解集空间，较多的变量，很快的得到优质解

## SAT问题：
- “布尔可满足性问题”：给定一个布尔表达式，是否存在一组布尔变量的取值使得该表达式的值为真。
- 部分CSP问题可以形式化为SAT问题（变量的取值只有0or1，或转化为bool变量描述），例如N皇后
- 针对SAT问题的DPLL算法：
  - 把整个表达式转化为合取范式，即子句内为并，子句间为交，这样发现子句错则整体错，快速发现错误早回溯
- CDCL算法：矛盾指引的子句学习（[conflict-driven clause learning](https://cse442-17f.github.io/Conflict-Driven-Clause-Learning/)）算法 
  - 在CDCL算法中，每当DPLL算法导致矛盾时，算法会分析矛盾的原因，并将其表示为一个称为矛盾子句的新子句 learning！
  - Boolean Constraint Propagation:在实现DPLL算法时，面对一个CNF formula, 一种优化是去找unit clause，也就是子句中只有一个变量没确定，且这个变量可以决定子句的对错（换句话说，其他的子变量都是false），此时则可以直接定此变量为真，继续搜索，从而快速剪掉变量为假的分支；此过程可以迭代直到没有unit clause，从而恢复普通搜索直到下一个unit clause出现
  - CDCL的核心是，当在搜索的过程中，如果我们发现当某些变量的特定值组合必然会（通过BCP）引领到false的话，可能说明这些变量可以被写为新的子句，同时我们直接回溯到新子句保护的变量的最后一个分叉，利用新子句去以新的顺序搜索，会避免DPLL算法中出现的不断的陷入这个implicit clause造成的conflict中
  - So how to learn?:可以在BCP发生时构建一个implication graph,去揭示哪些变量的哪个取值，通过哪个子句，会必然的引向false。highlevelly，我们通过指向false结果的有向边反推，则如果存在某个极小的节点簇使得false结果的所有祖父节点都【只】来自这个节点（且所有的子过程都是BCP的），则这个节点簇的取值可以构成一个新的clause。（而这种思想可能不止用于Bool变量的搜索）
  - 可以看链接中的一个Sudoku例子

## GAMES [Note5]
- adversaries involved
  - 我们初始时不确定竞争者会如何选择来对抗我们，需要新算法
- adversarial search problems classification
  - actions have deterministic or stochastic (probabilistic) outcomes
  - numbers of players
  - zero-sum(零和) or not
- deterministic zero-sum games
  - 确定性的结果（什么意思）
  - 零和：两方的利益总和为0，敌增我减，无法合作引申为所有对立问题
  - eg. 一方想最大化某个值，另一方试图最小化
    - 跳棋checkers:可解的问题 任何残局的解是确定的
    - chess:Deep Blue 
      - >use extremely sophisticated methods to evaluate over 200 million positions per second
  - 如何通过计算发展一个strategy or policy
- Minimax
  - motivationg assumption激励假设：对手总是做对我们最坏的选择
    - we maximize it,they minimize it.
  - 先从没有敌人阻碍的情形，建立：state value(the optimal score attainable by the agent which controls that state) 和 terminal utility（一个pacman例子，pacman在一维上左右游走，在尽可能少的步数下吃到豆子）
    - terminal utility 指的就是游戏有个总结的状态，在终结时我的某个utility即terminal utility，使其最大化是我的目标
    - 而其他我从初始状态开始可能到达的状态下，从此状态开始，接下来能实现的最大terminal utility(即这个状态变化子树内的最优值)，称为该状态的state value
    - 这就是一种启发函数，我们从后向前递推的判断：在状态a下向哪边走的state function更优，哪边就是更优的选择
  - 现在引入敌人ghost：
    - ghost的出现会使得状态树变为交替的层结构，两者交替做选择
    - 我们注意到整个过程是确定的，即如果后面的state value已知那么理性人agent会从后向前分析出每一步每个人的选择，那这是不存在博弈的。比如如例子中在进行1回合后的state value是可见的，那么后动的ghost选择必定分别是其中值更小的，那先动的pacman的两种选择的值也是确定的。
    > being wisely, Pacman is forced to hedge his bets and counterintuitively move away.
    - 回到公式，递归关系此时必须是一步之内的，下一步的人的选择确定了，即state value确定了，这一步的人才能有效选择
    - Hence，计算value的顺序应当是树的后序遍历(postorder traversal)
- Alpha-Beta Pruning
  - Minimax简单直接有效，但很慢，很多时候我们搜不完整个树 
  - 优化：alpha-beta 剪枝，怎么剪
    > Conceptually, alpha-beta pruning is this: if you’re trying to determine the value of a node n by looking at its successors, stop looking as soon as you know that n’s value can at best equal the optimal value of n’s parent.
  - 简单的说，由于第0层要最大子值，而子值的选取方式是子的子值中的最小值，如果子值一计算完成为a，子值2的第一个子就小于a，那子值2的值必定也小于a，对于父来说子值2一定不会被选取，那么就不必计算了，可以直接剪掉
    - 这一特性直接来自于game tree的minimax交替特点，普通的树是不行的
  - 有时能带来相同代价下增加很多层的搜索，是一种优化，但并不能直接解决问题，因为我们目前的逻辑还是要从terminal state向前搜(which)
- Evaluation Functions
  - 没办法从结束计算，那自然我们想象设计一个启发函数，能只用几步后的信息做判断，从而减少运算深度和时间。那就需要把几步后的情况定为终结，并为他们选择尽量有用的evaluation function,让agent的选择仍尽量最优
  - 一种常见的构造：特性(feature)的线性组合：$$Eval(s) = w_1 f_1(s) +w_2 f_2(s) +...+w_n f_n(s)$$
    - feature是从一个状态里我们可能直接提取的量化的值，例如象棋中剩余的各类棋子的个数，围棋的目等等，特性通常是很多方面的，可以写为一个向量，从而基于其重要性来加权求和
  - 其他的：nonlinear evaluation functions based on neural networks are very common in Reinforcement Learning applications. 
  - 记住Evaluation function的目的是尽量让我们做更多更优的选择，并应以此Tuning我们的function
- Expectimax
  - minimax针对最优敌人优化，有时候我们会面对随机敌人
  - 则改变minimizer返回的utility为某个random性质的数学期望，成为expected utility
    - 我们可以任意的设定概率分布以满足模型的需求（面对无限智能的敌人，那就是mininum的概率为1）
- MCTS
  - ideas:
    - Evaluation by rollouts: From state s play many times using a policy (e.g. random) and count wins/losses.
    - Selective search: explore parts of the tree, without constraints on the horizon, that will improve decision at the root.
  - 改进：
    - 我们不想平均的随机的搜索所有步骤，如果短时间内发现某个方向胜率很低，那应该更多的去花时间检验其他方向中哪个更好
    - 同时，在表现相近的方向中，如果有测试次数很少的方向，那其表现的可信度较低方程较大，我们更倾向于花时间在它身上去确认其表现
    - UCB：trade-off between “promising" and “uncertain’
      -  表达式：
   - UCT algorithm:
     - 4-step cycle
     -  
  - lab.feedback:
    - simulation中，通常在走一定步数内无法到达WinorLose,需要以演化后状态的启发函数返回，从而达到类似胜率的效果
    - 可以用启发式前进代替随机模拟，同时UCB也可以掺杂启发函数，从而更有方向性地搜索
      - 但一定要保留一定的随机性，否则一些不完善的启发函数会使agent被困在某个状态里（比如一个迷宫的死胡同）不断stop
    - 很难设计出一个针对所有可能的情况都良好的、易于实现而便于计算的启发函数，总是存在人脑无法预测到的错误情况
      - 更好的启发函数设计：机器学习
 - General Games
   - maybe not zero-sum:更广泛的博弈问题
     - multi-agent utilities
     - 每个人有每个人的utility，每个人只关心自己的utility并做出决策
     - 但事实上，这如果每个人有更高的智能，他们会发现他们的决策影响着后人的决策从而反馈回他们自己的utility，那或许他们就不是在自己的layer上选择max那么简单，这需要更多的计算来实现

## 机器学习基础
- in a word: data&output-->program
- 一些分类：
- 学习方式：
  - 监督学习模型：这类模型的训练数据包含输入和输出的配对，即已知每个输入应该对应什么输出。例如，分类问题和回归问题都可以通过监督学习来解决。

  - 无监督学习模型：这类模型的训练数据只包含输入数据，没有输出数据。无监督学习的目标通常是发现数据的内在结构，例如聚类和降维等问题。

  - 半监督学习模型：这类模型的训练数据包含一部分输入和输出的配对，以及一部分只包含输入的数据。半监督学习旨在利用未标记数据来提高模型的性能。

  - 强化学习模型：这类模型是基于智能体（agent）与环境进行交互的学习方式，强化学习的目标是通过智能体与环境的交互来学习最佳的行为策略。
- 接下来我们看一下按目的分类的模型
### 判别式模型
- 基本目标：构建一个包含参数的函数作为模型，将输入映射到一个数值或类别上（统称为label）
  - 学习过程：通过调整参数来拟合到训练数据上
    - 如果需要映射到连续值上，则为回归
    - 离散值则为分类
  - 评估：
    - 在训练集上学习，去降低训练集上的误差
    - 在测试集中测试，想要同样得到可以接受的误差，从而证明有泛化能力，避免过拟合
- k近邻算法
  - 不用训练，只是拿着训练集，看测试输入的周围最近的k个训练样本中更多的标签，来预测测试样本的标签
  - 一个例子是判断一个地点属于哪一个国家，看它离的近的点中哪个国家更多即可；
  - 但缺点：
    - 需要样本间的边界较为“平直”
    - 在更多模态的问题上，距离很难定义
    - 同时在高维下，距离的差别变得诡异，维度越高点更倾向于分布在边界而非近处，距离很难衡量真正意义的“样本接近”
  - k-NN是典型的非参数模型，没有参数参与，纯粹依靠原始的训练集
  - 而对应的是参数模型，通过训练合适的参数来拟合训练集，生成参数模型，去预测新的输入
- 线性回归
  - 线性模型：$f(x)=w^Tx+b$；w的分量构成每个维度的权重，b为整体的偏置
  - 评估误差：损失函数
    - 平方损失函数，所有点的预测值与真值的差值的平方求平均值（最小二乘法）
    - 最小化该函数，需要一些方法改变参数的方法
  - 梯度下降；沿着梯度反方向以超参数$\alpha$的幅度改变参数向量，从而减少误差值，直到无法再下降（下降足够缓慢）
    - 问题：可能陷入局部最小值而无法到达全局最小值
    - 但如果目标函数是凸函数就一定能这样找到最小值（凸函数不会有两个低谷），这就是凸优化问题；线性回归问题恰好是凸函数（Hessian半正定），因此可以梯度下降
    - 同时注意选择合适的超参数$\alpha$，保证下降搜索的速率足够快但不会因为幅度过大而不断错过最低点
- Empirical Risk Minimization (ERM)
  - 线性回归是ERM的代表
  - 经验风险最小化框架：确定模型，确定损失函数，调节模型参数以最小化损失（通常可以采用梯度下降）
  - 区别只是模型和损失的选取和定义
  - 而对于分类问题，一个难点在于没有数值，也就没有了距离和排序，应该如何建立模型和损失函数
- 逻辑回归
  - 对于分类问题，首先是二分类问题，能不能用类似的思路
  - 沿用Loss Function模型：含参的初等函数通常值域是实数域，需要映射到二分类中(def y= 1or-1)，因此引入$sign(f(x))$，以0为界限分到两类中
    - 误差函数：问题出现了，如果我们直接去求差得到误差求和：零一损失，这样会导致得到的是阶跃函数，无法梯度下降
  - 对于分类问题，差值是没有意义的，预测只有正确与否，那么预测一种分类的概率更有价值
    - 通俗的说，模型告诉我们一个输入有多大概率属于某一类，这样可以检查训练集中我们猜的有多对，显然对于正确的label，更高的概率预测是好于较低的概率预测的，这种可操作空间是以0为界的sign函数做不到的
  - 最大似然估计：使用概率论的工具，我们认为这是这种分类是一种概率事件，即对于任意输入，输出遵循一种概率分布，这里则是一个二元分布列$$p(y|x;\theta)$$其中参数$\theta$控制对于输入x，输出各个y的概率。通过建立这种分布模型，可以带入训练集，如果假设训练样本间独立，那么要求带入所有正确label的概率乘积最大是自然的；为了计算上的方便，通常转化化为对数求和最大化要求。
    - 常用的概率模型：把线性模型的R值域用sigmoid函数映射到[0,1]上，作为正类的概率；同时$y=\pm 1$保证了概率都可以写为$p=\sigma(y*f(x))$的形式，帮助化简
    - 得到形如$$\min \frac{1}{n} \sum(log(1+e^{-y_i(w^Tx_i+b)}))$$的要求，又回到了类似最小化损失函数的形式，因此这个对数损失函数被称为交叉熵损失
  - 交叉熵损失同时满足：
    - 是零一损失的上界
    - 连续可微凸函数
    - 最小化的同时，也达到了最小化零一损失的目的
    这种损失函数称为替代损失函数。同样的，把零一损失放大为一种线性函数的做法也是构造一种替代损失函数。
  - 逻辑回归训练
    - 梯度下降：发现梯度有$1-p$项，说明p接近1，拟合充分时，梯度很小
- 多分类问题
  - 一种思路，就是把做k次二分判断；缺点：没有对称性，无用代价太大。
  - Softmax回归
    - 很自然的想到对每个数据训练k个判断属于哪一类的概率模型$f_i(x)$，并归一化
    - 归一化函数Softmax，以$e^{f_i(x)}$作为权重归一化
      - 指数化会放大差距
    - 仍用最大似然估计，仍取对数和
- 过拟合现象
  - 如何避免过拟合：正则化
  - 在损失函数后加入正则化项来一起优化，用于惩罚过于复杂的模型：$$\lambda*R(f)$$ $\lambda$作为超参数，R对应过拟合的原因来设定
  - 可能的情型：
    1. 某些特征维度过度支配了预测值：
       - R设为参数平方和，惩罚过大的参数（L2正则化）
    2. 某些没有用的特征参数参与了预测：
       - R为参数和，鼓励参数为0（L1正则化）
- 超参数与模型选择
  - 模型和超参数都是作为训练前设定，如何判断设定是否合理
  - 从训练集新分出验证集：
    - 使用超参数和模型组合在训练集训练，在验证机上比较，选择表现最好的超参数和模型组合
    - 再在测试集上测试，估计泛化能力
  - k-折交叉验证：如果验证集不够大，那就把训练集分为k份，每次用一份当验证集，剩下为训练集，轮回k次，得到表现更好的组合。
- 决策树
  - 在线性模型处理问题的方式中，逻辑复杂性很低：给一个数据进去，经过模型一次判断就输出结果；或者在线性空间中，只凭一个超平面就划分了两类；
  - 更有逻辑的分类：决策树
    - 根节点包含样本全集
    - 每个非叶节点对应于一个（特征）属性测试；其包含的样本集合根据属性测试的结果被划分到子节点中
    - 每个叶节点对应于决策结果（取多数类）
  - 本质上，决策树是一种通过多维度的判断得到最终结果的方式，一个树型的分类模型
  - 理想的分类结果是，每个叶节点只包含同类别的训练样本（提升纯度），这说明判断是有意义的
  - 如何找到这样的判断划分策略：
      - 如果我们手上已经有一些特征，以及每个特征对每个训练样本的结果，那目标就是找一个判断逻辑（一个树结构），使得在每一个叶子节点得到尽量纯的分划，并规定叶子节点对应的二分类判断，这样对于测试集我就可以沿用这个判断逻辑来给出预测的标签
    - 训练：递归地使用当前最好的属性对训练集进行划分，直到纯度达到要求
  - 如何定义纯度：
    - 熵:在信息论中，熵被定义为一个随机变量的不确定性
      - 定义：某个事件发生的概率越小，包含的信息量越大，因此用$\log_{x}\frac{1}{p(x)}$来表示信息量
      - 一个离散型随机变量的信息熵就是可能性对应的信息量的数学期望
      - 显然概率越均匀，不确定性越大，熵越高
      - 同时熵也与总数量n有关，当概率完全均匀分布时，$H=\log_{2}n$
    - 对联合概率分布可以类似的定义联合熵
    - 条件熵：
    - 条件熵描述在已知随机变量𝑋的条件下随机变量𝑌的不确定性（注意我们不指定X的取值）
      - 对条件概率可以定义信息量为条件概率，而信息量的权重为联合概率，并对x,y求和
    - 熵的可加性：
      - XY联合熵=X的熵+X为条件下Y的条件熵
      - 表现了一种可叠加性
    - 互信息：
      - $I(X,Y)=H(X)+H(Y)-H(X,Y)=H(X)-H(X|Y)$
      - 这后一式表现了X的混乱程度减去在确定Y后X的混乱程度（反过来对称），即Y的确定多大程度上帮助减少的X的混乱，即Y中包含的X信息，也就是互信息
      - X,Y相互独立时，此式自然为0
  - 信息增益
    - 用信息熵度量样本集合𝐷的标签纯度
      - 即把同一标签归为同一事件，把同一标签的占比作为概率，代入信息熵
      - H(D)越低，纯度越高，H(D)=0即全纯
    - 属性𝐴对集合𝐷的信息增益：
      - 利用A将集合分为m份，分别求熵并加权叠加，而总熵的下降值说明A对D的纯化程度，称为信息增益
      - 类比此前的条件熵和互信息，实际上此值即标签和属性A的互信息
    - 划分原则：在节点处，选择信息增益最大的属性来作划分
    - 问题：实际上以序号做划分，分成n类，信息增益最高，但没有价值（实际上因为对分的类的数量不同的属性之间比较信息增益没有意义）
  - 增益率：
    - 信息增益与A自身的分类熵($H_A(D)$)的比值
    - 即A对D作出的分类本身不能太复杂，否则可能不具有泛化性能（比如序号），因为属性本身的信息很可能是不靠谱的
      - >一定程度上缓解了属性本身带来的高信息增益
    - 划分原则：在节点处，选择增益率最大的属性来作划分
  - 基尼指数：
    - 另一种方法，二次式
    - $ini(D)=1-\sum(\frac{\left |  D_k \right | }{\left |  D \right | })^2$
    - 利用属性A对D分类后得到每个集合的平均基尼指数，选择最小的属性
- 回归树
  - 如何类似熵的衡量一个连续属性对纯度的影响，以及当标签为连续，如何定义分类和纯度；这是复杂的问题
  - 可以用类似方差的L2 LOSS手段
- 随机森林
  - 集成学习
    - 之前讨论的线性模型，决策树，都是以一个模型学习出一种判断方法
    - 对于同一问题，多种模型都能给出方法，那尝试寻找一种方式去结合这些方法往往能更进一步
      - >集成学习的优点在于可以利用多个个体学习机的优势，提高整体的学习能力和泛化能力，从而达到更好的性能。集成学习可以有效地降低个体学习机的过拟合风险，提高模型的鲁棒性和稳定性。另外，集成学习还可以解决数据不平衡、噪声数据等问题，提高模型的分类性能。
      - >集成学习 = 多个个体学习器 + 结合策略
    - 分类：
      - 基于同质的个体学习机：
        - >Bagging、Boosting和随机森林等，主要是通过构建多个同种类型的个体学习机，从而提高整体学习能力和泛化能力。
      - 基于异质的个体学习机：
        - >神经网络集成、深度置信网络和深度学习网络等，主要是通过组合多个不同类型的个体学习机，从而利用不同个体学习机的优势，提高整体的学习能力和泛化能力。
  - 例子：随机森林
    - 基于决策树
    - 结合策略：样本扰动+属性扰动
      - 随机选择样本：随机森林采用有放回的随机采样方式，从原始数据集中随机选择一部分样本，构成一个新的训练子集。这样可以使得每个决策树都有不同的训练样本，从而减少过拟合风险。
      - 随机选择特征：在每个决策树的节点中，随机选择一部分特征用于划分，而不是使用所有特征。这样可以使得每个决策树都有不同的特征划分方式，从而增加决策树之间的差异性，提高整体的泛化能力。
     
- 支持向量机(Support Vector Machines)

## 神经网络
- 发源：
  - 首先，线性模型提供的自由度太少了，类型可能具有线性不可分的情况（eg. xor操作）
  - 树结构引入了非线性的方式，能否更进一步：图结构
  - 同时，树结构需要先验的给出特征，对于图像这种数据，能否自动提取特征
- 多层感知器
  - 线性回归等模型是一步操作出结果，输入直接到输出，就像一个单层的感知器
  - 多层感知器则是在输入输出间添加隐藏层，层的元数可以自由选择
  - 层之间所有的神经元（简称元）都有带权连接$w_{ij}$
  - 正向传播：
    - 下一层的每个元的值可由上一层的所有元的线性求和，叠加激活函数得到，直到正向传播到输出层
    - 激活函数的选择影响着感知器之间的联系
    - 比如对二分类，可以在输出层用sigmoid函数作为激活函数，输出正类概率
    - 对于多分类问题，输出层设立多个元，用softmax生成每个元对于的类的概率
- 如何训练
  - 每层间的每个权值和偏置都构成了参数，为了做梯度下降，要求出每个参数对输出层的梯度
  - 过于复杂的结构，很难直接给出表达式；且结构间有关联————反向传播
- 反向传播(Backpropagation)
  - 基于复合函数偏导数的链式法则：z与x直接隔了一层中间函数f_i，则z对x的偏导等于所有z->fi->x的链式的求和
  - 因此只要我们获得了上游层（反向传播意义的上游）的变量关于输出的偏导，再结合本元到上游层的偏导关系，对上游层的每个元作链式再求和即得到本元关于x的偏导
  - 注意，在反向传播的过程中，我们应该记录每个元值和每个权值的偏导，其原因在于权值的偏导用于梯度下降，而元值不是参数，但下一层的权值直接影响的是本层的元值，因此传播需要元值的偏导

## CNN
## RNN
## GNN

## 计算机视觉
### 经典的图像分类算法
- 图像表示
  - 像素为单位，每个像素占一定的bit数
- 基本思路
  - 通过提取特征，来得到点在特征空间里的位置
  - 通过聚类筛选类内的共有性质，得到分类器
- 特征提取算子-HOG(梯度直方图)
  - 动机：梯度可以凸显边缘的位置和方向，从而提取主要的特征；适用于行人检测
  - 步骤：
    - 先做灰度映射和gamma矫正，得到一个可计算的灰度图
    - 通过，计算cell内每个点的梯度方向和值，叠加来得到计算每个cell中总体上在那些方向的斜率更大，即为HOG的向量
    - 每4个cell组成block并归一化，列举所有block得到图片HOG
  - 其他的还有
    - Haar特征
    - SIFT特征
- 分类器
  - 已知特征，如何确定分类
  - 最近邻法：
    - 拿待检测图在查找库中找，找到距离（可能是基于特征向量的某种函数）最近的，即定为该类
  - 线性分类法：
    - 通过在特征空间中画直线（或高维超平面）来分割空间成很多块，不同类各占一块，依照在哪块来判断新输入的类
    - Fisher线性判别：
      - 为了找到两个类间最合适的分割线，让他们在法线上投影，使得类内投影最近、类间最远的即为合适的法线方向，也就得到合适的分割线方向
    - 支持向量机SVM：
      - 应找到分界面使得样本到分界面的最小距离最大化
      - 这样可以尽量提高出现在现有训练集的聚集区域之间的样本的准确性
      - 数学表达：$$max(1/||w||)s.t.y_i(w^Tx_i+b)\geq 1$$ 其几何意义即要求线正确的将两类分开在$w^Tx_i+b=\pm 1$的两侧，而最大化目的即使这两条线间距尽量远
- 全连接神经网络
  - 通过人工神经元自动学习图像特征（不需要预设），直接输入所有像素，在多层全连接神经网络下，输出各个种类的概率值（详见CNN）
  - LeNet
  - AlexNet
- 图像数据增强
  - 通过给已知集增加变化和噪声等，得到更多的测试集，以检验泛化性

### 三维重建
- 动机：从二维图像，分析三维信息，来重建三维数据
- 三维如何投影到二维上：
  - 针孔模型：小孔成像
    - 本质上即从相机光心，以角度为目标变量做投影
  - 摄像机成像过程
    - 从地系，旋转平移变换到相机系
    - 从相机系，小孔成像，投影到焦平面，为二维成像系
    - 再将成像系平移为适合处理的图像
  - 基本公式
    - 对于相机系P=(x,y,z),最后变为P*=(u,v)，有 $$v=f\frac{y}{z}+c_y\:,u=f\frac{x}{z}+c_x$$
    - 将P，P\*添加一个齐次坐标，然后写为矩阵形式，得到z=1下的 P\*=KP 其中K为内参矩阵
      - 齐次项参数是待定的，其意义是图像空间没有绝对的大小，因此如果多个图像之间需要关联，齐次参数可以帮助对应
    - 外部，相机系返回地系，即外参矩阵变换
- 三维重建：基于对应点重建
  - 首先，基于小孔：点对应这一条过光心的线，从一个二维向量推出三维向量是不可能的，具体体现在原始z的信息我们无从得知
  - 人眼：双目视觉感知深度
  - 基于双相机图像中的对应点关系，重建点的空间位置
  - 即同一个空间位置，通过两个不同的映射矩阵会映射到一组（乘以齐次项参数的）对应点上，解出这个复杂的方程可以得到齐次项参数和三维位置xyz
  - 问题在于，怎么确定谁和谁是对应点
    - 利用特征点描述子，进行特征提取和匹配（以SIFT为例）
      - 检测关键点：提取图像上具有特殊性质的点；
      - 生成关键点描述子：对关键点附加详细的信息(局部特征)；
      - 关键点匹配：通过两方特征点（附带上特征向量的关键点）的两两比较找出相互匹配的若干对特征点，也就建立了景物间的对应关系。
    - Scale-invariant Feature Transform
      - 动机：做高斯滤波等效于尺度变换（近大远小，近清晰远模糊），利用高斯滤波得到尺度信息
      - 对不同阶数的高斯滤波做差分，可以得到尺度空间极值点（在尺度内和相邻尺度内都是极值点）

## NLP
- 上下文无关的文法Context-Free Grammar
  - 只关注句子内部结构
  - grammar 是句子的生成规则，一个描述句子结构的树结构
    - 从S开始，自顶向下分解句子为短语，分解短语为短语，直到分解为词（终结符）
    - 当然我们发现这样的分解方式有很多可能性，句子分解为单句或两句与连词，名词短语是否有形容词，动词短语是否有副词，是否需要介词短语，从句，等等
  - 为此我们规定句法范畴（短语的大类：NP,VP,PP,Adjs,RelClause），他们概况了句子的可能拥有的主要结构（第一层子节点）
    - 建立句法范畴对应的生成规则，即每个句法范畴可以由哪些子句法生成
    - 再向下，每个子句法可以生成子句法，或实例化为终结符（即真实的单词），后者称为词典 
      - 分为开放类和封闭类：名词这样的可以不断扩充的，和介词这样的数量相对固定的
    - 生成规则的形式：$A\rightarrow B\ C\ D$，即A可以生成BCD，BCD可能是终结符，也可能是句法范畴
    - 同时，设定生成规则的概率：$P(A\rightarrow B\ C\ D)$，即A生成BCD的概率；
    - 这样可以自定向下生成句子来与实际句子适配，从而解析句子
    - 缺点：这种生成的方式，可能重复递归的生成相同的子结构，容易陷入无限循环
- 句法分析——CYK算法
  - 动机：想直接拿待检测的句子，向上合并以分辨其是不是符合语法规则
  - 为此，我们需要一个算法，可以自底向上解析句子
  - 规则：CNF：核心为$A\rightarrow B\ C$，其中B和C是短语；
    - 同时任何短语都可以解释为一个词，作为终结符；
    - 同时S可以解释为空集，表示句子是空的；但其他短语不可以解释为空集
    - 任何短语都可以有多个解释，只要满足CNF即可
    - 任何语法都可以转换为CNF
  - 算法：自底向上，每次解析两个短语，然后根据生成规则，找到可以生成这两个词的句法范畴，然后将这个句法范畴作为一个新的词，继续向上解析，直到解析到S，即句子
    - 借助一个三角形图标实现，从下到上，从左到右，每个格子代表一个短语，每个格子内部存储一个句子范围（比如说从字符1-3构成的短语）的所有解释，即句法范畴
    - 从而实现动态规划，每个格子的解释，都可以由下面对应位置两个格子的解释合并而来
  - 问题：如何找到可以生成这两个词的句法范畴——带有概率的生成规则
    - 通过生成规则的概率，找到概率最大的A，即$P(A\rightarrow B\ C)$最大的A
    - 算法：
      - A*搜索：在CYK算法的基础上，加入启发式搜索，即每次合并两个短语时，选择概率最大的A，而不是遍历所有可能的A
- n元模型 n-gram
  - 长度为n的连续符号序列
  - 比如三元模型，就是句子中三个连续的词
  - n元模型可以用来预测和生成，或检测，是一种统计手段
  - 但首先我们要解决标记化问题，如何分出词，分出句
- 分词 Tokenization
  - 把文本中的内容分成Tokens来处理，可能是分成word，也可能是分成sentence，包括标记标点符号
  - 分word：英文可以直接按空格分，中文需要分词
    - 即使是英文中，也有'can't'，o'clock,well-cut这样的词，包含或不包含符合，需要分析
  - 分sentence：按标点符号分
    - 但是有些标点符号不是句子的结束，比如说Mr.，U.S.A.，这样的缩写，需要分析
  - 中文分词
    - 基于字符串库的匹配：通过和词典里的词匹配
    - 基于机器学习：
      - CRF(条件随机场)、HMM(隐马尔可夫)、SVM、深度学习(BiLSTM-CRF)等
- 基于马尔可夫模型的文本生成
  - markov链是无后效性的，下一个状态只和当前状态有关，和之前的状态无关
  - 但状态不一定对应单个单词，也可以是一个n-gram，从而用递归的方式生成文本
  ```markdown
  数据预处理：首先，需要对原始文本进行预处理。这包括分词（对于基于单词的模型）或字符分割（对于基于字符的模型）。分词将文本分割成单词序列，而字符分割将文本分割成字符序列。

  统计n-gram频率：接下来，统计训练文本中的n-gram（n元组）的频率。n-gram是由n个相邻的单词或字符组成的序列。例如，对于一个基于单词的模型，可以统计双词组合（bigram）或三词组合（trigram）的频率。

  构建马尔科夫模型：使用统计的n-gram频率构建马尔科夫模型。对于每个n-gram，记录其后继单词或字符及其出现的概率。这样就形成了一个马尔科夫链，其中每个状态表示一个n-gram，转移概率表示后继单词或字符的出现概率。

  生成文本：根据马尔科夫模型，开始生成文本。从一个起始状态（初始n-gram）开始，根据转移概率选择下一个单词或字符，并将其添加到生成的文本中。重复这个过程，根据当前状态和转移概率选择下一个单词或字符，直到达到所需的生成长度或达到终止条件。
  ```
- 分类问题：判断文本属于哪个类别（eg.情感分类）
  - 词袋模型：直接把文本转换为向量，每个维度代表一个词，值代表这个词在文本中出现的次数
    - 问题：太稀疏，维度太高，无用信息很多
  - 朴素贝叶斯模型：
    - 基于贝叶斯定理，假设每个词都是独立的，即每个词都是独立的特征，从而可以将每个词的概率相乘，得到整个文本的概率
    - 逻辑：通过一系列变换，把条件概率P(类|文本)转换为P(类)*P(词|类)的累乘，从而可以通过比较每一类的P(类)P(文本|类)的大小，并归一化，来判断文本属于哪个类别的概率
    - 问题：如果某个词在训练集中没有出现，那么P(词|类)就为0，从而导致整个文本的概率为0，这是不合理的
      - 解决：拉普拉斯平滑，即在每个词的出现次数上加1，并改写P(词|类)的条件概率使其仍为1/n，n为总词类数，从而避免出现0的情况
- 词表示
  - 独热表示:每个词都是一个向量，向量的维度为词典大小，只有一个维度为1，其余都为0
    - 问题：维度太高，无法表示词与词之间的关系
  - 分布式表示：每个词都是一个向量，向量的每个维度都有值
    - 理论：上下文相似的词，其语义也相似。词的语义由其上下文决定
    - 分布式表示可以基于很多形式，比如基于共现矩阵，基于神经网络，基于矩阵分解等
    - 其核心在于如何表示上下文，即如何定义词与词之间的关系
  - word2vec
    - CBOW
    - Skip-gram
    - (we'll talk about it later)
    - _！_
- 基于神经网络的自然语言处理
  - 文本情感分类应用
    - 神经网络主要是训练的方式，但如何把文本转换为向量，如何表示文本，是一个很重要的问题
      - 人工设计特征：比如一些负面词，正面词等，但是这样的特征很难设计，而且很难表示
      - 基于word2vec/GloVe的文本特征
  - 前馈神经语言模型：基于前词上下文预测接下来的词
    - 类似一个基于n—gram的分类模型，输入是一个词的上文的n个词，输出是这个词
  - 递归神经语言模型：
    - RNN递归生成
- Transformer：Seq2Seq
  - 比如：神经机器翻译
    - 传统的机器翻译：基于短语的翻译，即把一句话分成很多个短语，然后翻译每个短语，再组合起来
    - 神经机器翻译：基于神经网络的翻译，即把一句话作为一个整体，输入神经网络，输出另一种语言的句子
  - 编码解码架构
    - 编码器：把输入的句子转换为一个数学表示，即一个向量
    - 解码器：把编码器的输出作为输入，再输出另一种语言的句子
    - 同样，可以使用基于RNN的编码，并用类似的隐藏状态传递机制来生成解码
  - 注意力机制：(don't understand)
    - 生成解码器的每个时间步的输出时，注意力机制用于帮助模型关注输入序列中与当前输出相关的部分。
    - 注意力机制通过计算每个时间步的注意力权重，将输入序列中的不同部分对当前时间步的输出贡献进行加权。这样，解码器可以根据输入序列的不同部分调整其生成的输出。
    - 包括多头等，找找别的资料

## 知识图谱
- 知识图谱：知识图谱是一种语义网络，它以图的形式表示知识，图中的节点表示实体，边表示实体间的关系。
- 知识抽取：从非结构化文本中抽取结构化的知识
  - 命名实体识别：识别文本中的实体，比如人名，地名，机构名等
  - 关系抽取：识别文本中的实体间的关系
  - 事件抽取：识别文本中的事件
- 知识表示：
  - 意义：用易于计算机处理的方式来描述人脑的知识，并支持通过符号之间的运算来模拟人脑的推理过程。
  - 逻辑表示：一阶谓词逻辑
  - 命题与逻辑联结词
    - 命题是一种陈述，它要么为真，要么为假，具有真假意义
      - 不可再拆分的陈述句构成的命题是原子命题（简单命题），用一个符号字母表示 eg. P
    - 逻辑联结词：用来连接命题，构成复合命题
      - 否定：非P，表示P的否定，记为~P
      - 合取：P且Q，表示P和Q都为真，记为P∧Q
      - 析取：P或Q，表示P和Q至少有一个为真，记为P∨Q
      - 条件（蕴含）：如果P，那么Q，表示P为真时Q也为真，记为P→Q；
        - (P→Q)当且仅当(~P∨Q), 故有谓：条件恒假则蕴含恒真，实际上蕴含是很弱的命题
      - 等价：P当且仅当Q，表示P和Q真值意义相同，记为P↔Q
  - 个体词、谓词与函数
    - 个体词：表示具体的个体，比如人名，地名，机构名等
    - 谓词：表示个体的性质，或个体之间的关系 P(x)表示x具有性质P,P(x,y)表示x和y具有关系P,其中个体元的个数称为谓词的元数
    - 函数：表示从个体到个体的映射，比如父亲函数，F(x)表示x的父亲；注意映射到的个体即函数的输出应该唯一；
    - 函数的输出是一个个体，而谓词的输出是一个命题
  - 其他逻辑量词：
    - 全称量词：∀xP(x)，表示对于所有的x，P(x)都为真
    - 存在量词：∃xP(x)，表示存在一个x，使得P(x)为真
  - 其他表示法：
    - 一阶谓词逻辑的表示法是一种符号逻辑，它使用符号来表示命题，但是符号逻辑不易于计算机处理，因此还有其他的表示法，比如：
      - 语义网络：用图来表示知识，图中的节点表示实体，边表示实体间的关系
      - 产生式规则：用一种规则来表示知识，比如IF-THEN规则
      - 语义网络和产生式规则都是一种非符号逻辑，它们易于计算机处理，但是不易于人理解
- 知识推理：
  - 从收集到的知识中推理出新的知识和关系
  - 基于逻辑表示的推理：
    - 规则：逻辑等价式：两式等价，当且仅当它们的真值表相同
      - P→Q等价于~P∨Q
      - 各种分配律，德摩根律等
    - 自然演绎推理与归结演绎推理：
      - 自然演绎推理：通常是由一组已知为真的事实出发，通过一系列推理规则，推导出新的事实
        - 比较像自然人的推理过程
      - 归结演绎推理：依据归结原理，将问题转化为多个子句，再进行相消化简，得到目标形式
      - 后者更适合机器进行演算
    - 归结演绎推理的过程：
      - 先将问题化为多个析取子式，放入子句集，再将结论否定化放入子句集；则如果问题成立，子句集不可能全为真；
      - 则问题为证明一个合取范式恒假，即一个SAT问题，亦可以直接通过子句间的推理来化简
  
## 智能机器人 wohoo！
- 机器人：能够感知环境，通过计算机程序来控制其行为的机器
- 机器人智能算法与系统：  
  - 机器人运动系统：
    - 输入：环境信息与状态信息+输入任务（目标）
    - 计算：运动规划
    - 输出：运动控制（更确切的是关节上施加的力矩）
- 环境感知与定位-->环境建模
  - 信念状态：环境是一个广泛的概念，我们用信念来表示机器人对环境的感知；机器人对环境的信念，是一种概率分布，表示机器人所感知的具有一定不确定性的环境状态
    - 其基本思想是机器人对新的状态的计算，是综合基于当前的信念状态和新的观测信息得到的，是一种预测
  - 定位：具体到影响决策的关键——定位问题
    - 定位的目标包括机器人自己的位置状态，包括关节等朝向状态，也包括定位其他物体
      - 位置定位：在简化的二维模型中，已知地图的情况下，可以结合地标来确定初始的位置和朝向，结合速度和角速度，可以确定后续的位置和朝向
      - 构建一个根据矢量v和w更新的位置状态转移函数，可以递推的得到机器人的位置状态
      - 当然由于误差的存在，这样的判断系统可能随着噪音的引入而发散，也可以使用多个传感器来进行定位，包括进行高频的实时校准
    - 由于误差总是存在的，我们引入一些算法和模型来表示并应对这些噪音带来的影响
  - 重点介绍 蒙特卡洛定位(Monte Carlo Localization, MCL)：
    - 基于粒子滤波器(particle filter)的定位，使用一系列对应状态的粒子表示机器人的信念状态𝑷(𝑿𝑡|𝒛1:𝑡, 𝒂1:𝑡−1)
      - 非常类似量子力学中的波函数，我们用粒子的分布去表示机器人的状态分布的概率，在定位中即表现为在地图上的位置分布
      - 起初，粒子先验的随机生成，随着观测的发生，信息即经验的引入，粒子的分布逐渐收敛至高后验概率的区域，越多的测量发生，其分布的区域越收敛，直到足够可信的确定机器人的位置
    - 从概率分布看，其数学思想表现为，通过输入机器人当前的信念状态（一个概率分布），对于当前信念状态叠加转移模型而对全空间积分，即得到了一个先验的转移后的概率分布，再乘以传感器模型对此概率分布和测量结果的吻合度衡量，从而得出一个后验概率分布，即机器人更新后的信念状态。这个信念状态包含了前一时刻的信息和刚刚发生的测量信息，因而准确性更高（公式ppt P26）
    - 而具体实现上，我们用蒙特卡洛法来采样实现——粒子滤波器算法：
      - 1.初始化：随机生成𝑁个粒子，每个粒子的状态𝑿𝑡∼𝑷(𝑿𝑡|𝒙0)；
      - 2.采样：根据粒子的权重，对粒子进行采样，得到新的粒子集合𝑿𝑡
      - 3.预测：根据运动模型并叠加合理的噪声，对粒子进行预测，得到新的粒子集合𝑿𝑡
      - 4.更新与重采样：根据观测模型（对粒子乘权重，为在该粒子处能获得已知传感器数据的可能性(似然值)），并根据一定的权重范围对粒子进行更新，得到新的粒子集合𝑿𝑡
      - 5.重复3-4步，直到收敛
    - 注意，由于机器人是在运动中的，因此实际上是一种链式的更新规则，类似RNN的马尔科夫链结构
  - 地图创建
    - 同步定位与地图绘制(SLAM)
- 运动规划
  - 路径+含时间的轨迹；一个纯运动学问题
  - 构型空间：能完全确定机器人状态的点构成的高维空间；其上可以存在（不构成碰撞）的点构成了机器人的工作空间
  - 运动规划问题：在给定的工作空间中，找到一条从起点到终点的路径，使得机器人在运动过程中不碰撞到障碍物；经典的连续状态搜索问题
  - 方法：
    - visibility graph：以在直线运动为基础，可见区域即可在一条直线的运动中到达的区域，选取紧挨着障碍物的直线，从而考察是否能构成离散化的路径搜索
    - 沃罗诺伊图式：总是在尽可能远离障碍物的路线中进行搜索
    - 单元分解：离散化空间
    - 随机运动规划(Randomized motion planning)：随机采样点集，加上起点终点，连接可以连接的直线，构成一个图，然后在图上进行搜索，找到一条路径
  - 快速探索随机树(Rapidly-exploringrandom trees (RRT))：
    - 逻辑：基于树结构的递进搜索逻辑
    - 算法过程：
      1. 维护一个树结构，树的节点为位置，边为可行走的路径，边的长度是实际的两点距离；初始化RRT树为起点，为根节点
      2. 从状态空间中随机采样一个点，找到RRT中距离最近的节点，以此为起点向采样点沿直线走stepsize长，得到一个新点；如果新点在可行工作空间中，则作为前述节点的子节点加入RRT，并更新边。
      3. 重复2，直到找到一个距离终点足够紧的点，可以直接连向终点；则根到终点的路径就是一个可行的运动规划
    - 缺点：
      - 由于是随机采样，面对狭小的可行通道时，每次搜索成功的概率很低，效率较低
      - 属于uninformed search，没有主动利用终点的信息
    - 改进：基于双向扩展平衡的连结型双树RRT算法
      - 同时也需要考虑随机点的采样策略如何优化
- 运动控制
  - 控制应当是闭环的，即应当有反馈
  - PID控制
    - 想要机器人到达某个位置，就需要知道当前位置和目标位置的差距，然后根据差距的大小，调整机器人的速度，使得差距越来越小，直到足够小，即到达目标位置
    - 首先想到P,比例控制，以距离为比例控制施加的力。
      - 问题：当外力存在时，会导致稳态误差
    - 引入I,积分控制，以过去的差距的时间积分为比例控制施加的力。从而当长时间陷入稳态误差时，积分项越来越大，会逐渐消除稳态误差。
      - 问题：仍存在过冲
    - 再引入D,微分控制，以差距的变化率为比例控制施加的力。从而当差距变化率越来越小时，微分项越来越小，构成阻尼，减小过冲和震荡。
  - 当然PID控制总存在相位延迟，需要构建其他模型或方法，来保证运动输出是如愿的

## 仿真
- 几何表达：
  - 如何描述空间中的形状，包括判断形状的内部和外部
  - 隐式表示和显式表示：
    - 隐式：f(x)=0 定义形状
      - 对于空间中的点，通过f(x)的值判断与形状的关系，较容易
      - 列出形状上的点，需要求解方程，较麻烦
    - 显式：给出形状上，各分量满足的参数方程
      - 在参数的定义域下，给出形状上的点，较容易
      - 判断与形状的关系较难
    - 两种表示在不同的应用需求中，对于不同的结构从构建到输出都各有特点，需要衡量
  - 对于复杂的形状构建需求，通常是已知形状的客观存在，如何处理为可用的表示
    - Signed Distance Function (SDF)：通过距离场定义形状
      - 定义空间中任意点到一个已经存在的形状上点的最近带符号距离为SDF，从而构建一个距离场，具体可以离散化的方式实现，从而构成一个场分布，来表示形状
    - 点云表示：有密集的点来表现形状，通常是基于探测数据直接得到的
    - 体素表示：将空间划分为小网格，网格包含边界则为1，不包含则为0，从而构成一个体素场，来表示形状
    - MESH（多边形网络）：记录定点坐标和边连接关系，通过其构成的多边形围成形状
      - 优点：存储自由度高
      - 难点：构建和处理的算法复杂
        - 判断点是否在形状内部，需要很多计算
    - Marching Cubes
      - 一种从三维数据中提取表面网格的算法
      - 通过类似体素的离散检测，并加以插值和连边策略，得到表达边界的网格
- 绘制与渲染：
  - 图像是二维平面（空间）上定义的颜色编码函数，矢量图是记录形状的参数，而点阵表示记录离散化的像素的颜色
  - 光栅化：将连续形状离散化成点阵图像表示的过程
    - 从投影的角度进行光栅化绘制：从物体投影到像平面，并进行近物遮挡远物的更新。其基本假设是物体的表面发出原生确定的光线。
    - 光线追踪：考虑光线会发生反射折射，从而由光路可逆原理，自像素上发出射线，在空间中追踪光线的传播和在物体上的交互，累加得到像平面上的颜色。如果没有遇到物体就显示背景色。是一种前者的逆向过程
  - 投影规则：最简单的绘制不考虑折射反射，即到一个物体就停止，计算此点的颜色。
    - 正交投影：所有射线平行的发出
    - 透视投影：所有射线共一点，该点位于平面的物空间的另一侧；近大远小
  - 着色：如何尽可能真实的模拟物体在环境光下显示什么颜色，以体现立体感——素描
    - 朗伯模型：假设物体表面是完全粗糙的漫反射模型
      - 首先考虑入射光：假设入射光是均匀的，在小区域内为平行光，则单位面积上的入射光能量正比与其有效界面，即正比于法线与入射光线夹角的余弦值，也即光强正比于该值
      - 再考虑反射光：假设物体表面是完全粗糙的，即反射光均匀分布在所有方向上，所有方向的反射光强是相同的（也即其按角度的能量正比于上述余弦值），且不会发生折射，即反射光的强度与入射光的强度成正比
      - 综上，我们得到朗伯模型下物体表面的着色规律：每个点的光强正比于法线与入射光线夹角的余弦值，以及其他表面参数，而与观测位置无关
  - 完成着色后，我们还要通过几何关系来判断某条光线应该选择表现哪个物体
    - 一种更广泛的思路是，给定空间中的透明度思路，直接按透明度进行沿光线有序的累加，得到最终的颜色
  - NeRF
    - 用神经网络来描述上述颜色/透明度场，从而实现由多视角的图像重建出物体的三维形状等应用
- 物理仿真
  - 基于计算的仿真：通过计算机模拟物理规律，来模拟物体的运动
  - 基本的假设是对时空的离散化，即将连续的时间和空间以某种方式划分为离散的区间，然后建立格点的特性以及格点直接的关系进行计算
  - 拉格朗日视角和欧拉视角：拉格朗日视角是以系统为中心，用拉格朗日力学来描述广义速度和广义坐标的关系，欧拉视角是以空间为中心，用欧拉力学来描述基于空间位置的速度加速度等关系
  - 欧拉积分：
    - 通过欧拉视角，我们可以得到物体在某一时刻的速度，然后通过积分得到下一时刻的位置
    - 但离散情况下，速度是在离散的序列元素上的，而位置的变换是发生在元素之间的；类似的，力往往可能基于位置，而力的发生（即速度的变换）也是在之间过程的。因此我们需要选择用n还是n+1格点下的位置和速度来计算下一时刻的位置和速度
    - 前向/显式欧拉方法：
      - 用n格点的速度和位置来计算n+1格点的位置和速度
      - 递推较为直接
    - 后向/隐式欧拉方法
      - 用用n+1格点的速度和位置来计算n格点的位置和速度
      - 需要解方程，较慢
    - 半隐式
      - 使用n的位置计算速度的变换，使用n+1的速度计算位置的变换
    - 需要注意的是，欧拉方法存在误差，误差会导致能量的不守恒，从而导致得到的解不稳定
      - 显式欧拉会导致高频振荡，不断向体系内注入能量，导致发散
      - 隐式欧拉会不断从体系内消耗能量，导致较快的收敛
      - 半隐式欧拉能比较好的平衡
      - 隐式欧拉是无条件稳定的，而显式欧拉和半隐式是条件稳定的，这主要取决于时间步长的选择
        - 而半隐式欧拉的条件稳定性是比较好的，不需要非常短的时间步长，因此在实际应用中，半隐式欧拉是最常用的
    - 流体仿真：我们还是放在games103里好好学好了
- 动画-角色动画 Animation！
  - 详见games015
  - FK记得分清楚是哪个关节的坐标系，是局部旋转还是全局旋转
    - 注意旋转的施加顺序和矩阵的乘法顺序
  - IK
    - ccd
  
## 多智能体
- 多智能体系统
  - 由多个智能体组成的系统，每个智能体都有自己的状态和行为，会基于决策做出行动，智能体之间可以相互交互，从而影响彼此的状态和行为；通常假设智能体是有理性的，即会基于自己的目标做出最优的决策
- 博弈论
  - 非合作博弈：
    - 零和或负和，强调个人的行为，认为无法达成有约束力的协议来保证合作，合作与背叛与否总是基于个人的利益
  - 合作博弈：
    - 正和博弈，假定有约束力的协议，以促进合作
  - 动态/静态博弈：
    - 静态博弈即所有人同时决策和行动；动态博弈即有序的轮流决策和行动
  - 完全信息/不完全信息博弈：
    - 完全信息即所有人都知道所有人的状态和行为；不完全信息即可能不知道所有人的状态和行为
  - 策略：纯策略与混合策略
    - 策略就是基于信息的决策函数，纯策略即确定性的策略，混合策略即基于概率的策略
    - 混合策略的收益是期望收益
  - 效用表
    - 效用表是一个二维表，行是自己的策略，列是对手的策略，每个元素是自己的收益 
  - 囚徒困境
    - 占优策略：当无法得知另一方的选择信息时
      - 当出现无论对方选什么，增加的某个选择总是优于另一个选择/至少一种情况下优于而其他不弱于
      - 称为强占优/弱占优策略
      - 理性参与者在完全独立的情况下总是选择占优策略
      - 但占优策略不是总存在
  - 帕累托最优
    - 没有其他结果是所有人都不变坏的情况下，至少有人都会更好的
  - 纳什均衡（Nash Equilibrium）
    - 定义:局域均衡点
    - 定理：在任何有限博弈（即参与者和策略集合均有限的博弈问题）中，都存在至少一个纳什均衡
    - 那么一个问题是如何找到这个纳什均衡
  - 双人零和博弈——所有的效用结果，两人代数和都是0
    - 例子：猜手指问题——不存在纯占优策略，因此采用混合策略
    - 此时参与者会想，无论对方选什么，我都会选一个使得对方收益最小的策略，即最小化对方的最大收益
    - 同时，我的策略应该使得我最坏收益最大，即最大化我的最小收益
    -  (Minimax Theorem)
      - 上述两个策略的期望收益是相同时，这个策略组合就是纳什均衡
  - 合作博弈
    - 我们更关注参与者的组合，我们希望各个参与者能够达成合作，但其中每个参与者仍是以自身的利益为出发点
    - 具有可转移效用的合作博弈：实际上我们对于合作博弈，我们可以先判断哪些参与者之间会结盟，再在结盟内部分配收益。可转移效用即结盟内部的收益分配是可转移的，是自由的。因此可以首先只关注如何结盟和结盟的总利益
    - 我们讲这类问题模型化为G(N,v);N是参与者的集合，v是定义域为N的所有子集的函数，v(C)是集合C即C中人结盟能得到的总收益,C称为联盟
    - 因此在博弈发生后，N会被拆成联盟的组合（一种分划），而拆分的情况有很多种可能，每种可能有各自的利益结果。这个结果可以表示为(CS,x),CS是分划的结果，x是每个联盟内部分配后得到的每个人的收益组成的向量；当
    - 分类：一些可能出现的特性
      - 超可加性：对于任意的联盟C1,C2， $v(C1∪C2) \geq v(C1)+v(C2)$ ,即联盟的总收益不会分裂后的收益之和
        - 但注意这并不说明联盟总会不断的合并，因为合并后的联盟的内部利益分配可能会使得有些子联盟倾向于独立
      - 凸博弈：对于任意的联盟C1,C2， $v(C1∪C2) \geq v(C1)+v(C2)-v(C1 \cap C2)$ , 即联盟的总收益不会分裂后的收益之和减去重复计算的收益，弱于超可加性
      - 简单博弈：收益函数是0-1函数，即只有0和1两种收益，常用于投票问题
    - 有了以上的模型，下面的问题就是如何确定联盟内的收益分配，x=(x1,x2,...)
      - 理想的收益向量满足
        - 对于整个大联盟，所有收益都被分配
        - 符合个体理性，即分配的收益不低于个体或子集以某种形式独立或加入其他联盟的收益
    - 合作博弈的核core：
      - 核是所有人的收益向量的集合，其中的收益向量满足
        - 对于任意可能的小联盟，小联盟内部的人的收益之和不低于小联盟的收益；这就说明这样的小联盟不容易从大联盟独立，里面总会有人的收益是下降的
      - 同理，核外的收益向量会使得有人不愿意加入大联盟
      - 博弈问题的核非空，表示大联盟可以成立
    - 但核内的分配只代表了人不会离开大联盟，但不代表分配是公平的；当然公平是什么也需要定义
    - 边际贡献：对于联盟C，边际贡献是指小i加入联盟C后，联盟的收益增加的部分
      - >直觉上，边际贡献更大的参与者应该获得更多收益分配
      - 无效参与者——对于任意原本不含i的联盟C，如果小i加入联盟C后，联盟的收益不变，那么小i就是无效参与者
      - 对称参与者：对于任意不含i，j的联盟C，如果i和j的边际贡献总是相同，那么两人对称
    - 公平性公理
      - 所有收益都分配到个人
      - 无效参与者不应该获得收益
      - 对称参与者应该获得相同的收益
      - 分配方式应该线性可加的，即联盟收益函数v和分配函数x是线性关系
    - 沙普利值
      - 由于每个人的边界贡献与他的联盟有关，而对于大联盟来说，所有人加入的顺序不同会导致每个人在加入时带来的边际贡献不同。因此我们可以考虑对于所有的加入顺序等概率发生，这时每个人的边际贡献的平均值，即沙普利值
      - 按沙普利值作为比例分配收益，可以满足上述公平性公理
  - 机制设计问题
    - 通过设计合适的规则，使一组智能体自发的完成特定的目标
    - 例子：拍卖