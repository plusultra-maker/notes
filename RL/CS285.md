# notes aboyt me listening cs285
## L1
- RL: agent interacts with environment
  - 没有成型的监督数据，只有reward函数（可能也没有），归根结底一个ground-truth的世界，我们要找出策略实现最优的结果，这个结果通常用reward函数来评价
- RDL: deeplearning 强调其不需要人工进行分解，强调用网络直接实现端到端的学习；
  - 而RDL则更进一步，不止于用DL的结果来进行策略，而是从感知输入直接到策略的reward做端到端的学习，这相较直接用DL的不确定性结果来进行盲目的策略学习，对于策略的结果更高效
- 几个优化的方向
  - imitation: 从已有的好策略在模仿学习
  - prediction：我们不总是能去试错，需要学习去预测，这样可以减少试错的次数，减少不确定性
    - model-based: 用模型去预测
  - learn to learn
    - learn reward： 没有天然reward，人工设定效果未必好，需要学习好的reward设定
    - 